{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph attention networks with Haiku Geometric\n",
    "\n",
    "This notebook contains a quickstart example on how to use [Haiku Geometric](https://github.com/alexOarga/haiku-geometric) to create graph attention networks \n",
    "and train them on the CORA dataset.\n",
    "\n",
    "[Haiku Geometric](https://github.com/alexOarga/haiku-geometric) is a graph neural network library built for [JAX](https://github.com/google/jax) + [Haiku](https://github.com/deepmind/dm-haiku).\n",
    "\n",
    "If wou want to know more about Haiku Geometric, please visit the [documentation](https://haiku-geometric.readthedocs.io/en/latest/).\n",
    "You can find there a more detailed explanation of the library and how to use it as well as the API reference.\n",
    "\n",
    "If you want to see other examples on how to use Haiku Geometric to build other\n",
    "graph neural networks, check out the [examples](https://haiku-geometric.readthedocs.io/en/latest/examples.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqK8sAz1zqFm"
   },
   "source": [
    "# Install and import libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b4kGLvByrVs",
    "outputId": "632fa935-6205-4b3f-a252-53cf0ffa6572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting haiku-geometric==0.0.2\n",
      "  Downloading haiku_geometric-0.0.2-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optax\n",
      "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.8/dist-packages (from haiku-geometric==0.0.2) (0.3.25)\n",
      "Collecting dm-haiku\n",
      "  Downloading dm_haiku-0.0.9-py3-none-any.whl (352 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from haiku-geometric==0.0.2) (4.64.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from haiku-geometric==0.0.2) (57.4.0)\n",
      "Collecting jraph\n",
      "  Downloading jraph-0.0.6.dev0-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax) (0.3.25+cuda11.cudnn805)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from optax) (4.4.0)\n",
      "Collecting chex>=0.1.5\n",
      "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from optax) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from optax) (1.21.6)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.12.0)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.1.8)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax->haiku-geometric==0.0.2) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax->haiku-geometric==0.0.2) (1.7.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from dm-haiku->haiku-geometric==0.0.2) (0.8.10)\n",
      "Collecting jmp>=0.0.2\n",
      "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: jmp, dm-haiku, jraph, chex, optax, haiku-geometric\n",
      "Successfully installed chex-0.1.5 dm-haiku-0.0.9 haiku-geometric-0.0.2 jmp-0.0.2 jraph-0.0.6.dev0 optax-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install haiku-geometric optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hcur1rPjzmr9"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import haiku as hk\n",
    "from haiku_geometric.nn import GCNConv, GATConv\n",
    "from haiku_geometric.datasets import Planetoid\n",
    "from haiku_geometric.transforms import normalize_features\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jn-0V7uzzvfF"
   },
   "source": [
    "# Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBmAmUEBzwMl",
    "outputId": "1a4d3695-5c50-474e-c0e7-7ffb3a6a5fbc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "NAME = 'cora'\n",
    "FOLDER = '/tmp/cora/'\n",
    "dataset = Planetoid(NAME, FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpmNbY0o1KfV",
    "outputId": "155196ad-cbd9-4ed4-ef96-02e770d4b12e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of graphs :\", len(dataset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NI1qS2Un1QdR",
    "outputId": "7e729e91-a435-4ba9-efb5-1aa1dd6d74b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes : 2708\n",
      "Number of edges : 10858\n",
      "Nodes features size : 1433\n"
     ]
    }
   ],
   "source": [
    "graph = dataset.data[0]\n",
    "print(\"Number of nodes :\", graph.n_node)\n",
    "print(\"Number of edges :\", graph.n_edge)\n",
    "print(\"Nodes features size :\", graph.nodes.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8VTBH4M2LiR",
    "outputId": "ab612c37-e59e-4825-8065-ee9afefd1215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples:  140\n",
      "Validation samples:  500\n",
      "Test samples:  1000\n"
     ]
    }
   ],
   "source": [
    "train_mask = dataset.train_mask\n",
    "val_mask = dataset.val_mask\n",
    "test_mask = dataset.test_mask\n",
    "\n",
    "print(\"Train samples: \", jnp.count_nonzero(train_mask))\n",
    "print(\"Validation samples: \", jnp.count_nonzero(val_mask))\n",
    "print(\"Test samples: \", jnp.count_nonzero(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iMD3HRfqJLf5"
   },
   "outputs": [],
   "source": [
    "# We will need these later during training\n",
    "train_labels = graph.y[train_mask]\n",
    "val_labels = graph.y[val_mask]\n",
    "test_labels = graph.y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acq4QJOh3Cd3",
    "outputId": "ec908fbf-df05-4feb-eb6c-a268d454e137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(jnp.unique(graph.y))\n",
    "print(\"Number of classes: \", NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ruJ_vdwvyMvy"
   },
   "outputs": [],
   "source": [
    "# Features are normalized\n",
    "graph = graph._replace(nodes = normalize_features(graph.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEd7ict92sNE"
   },
   "source": [
    "# Define GAT model\n",
    "We create here a model with 2 layers of [GATConv](https://haiku-geometric.readthedocs.io/en/latest/modules/nn.html#haiku_geometric.nn.conv.GATConv) from the [\"Graph Attention Networks\"](https://arxiv.org/abs/1710.10903) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7sdva_HU2uFI"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(jnp.unique(graph.y))\n",
    "\n",
    "# Hyperparameters\n",
    "args = {\n",
    "    'hidden_dim': 8,\n",
    "    'output_dim': NUM_CLASSES,\n",
    "    'heads': 8,\n",
    "    'dropout_attention': 0.15,\n",
    "    'dropout_nodes': 0.00,\n",
    "    'num_steps': 500,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 0.1,\n",
    "    'initializer': hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\") # glorot (truncated)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iZlvjsto3f5n"
   },
   "outputs": [],
   "source": [
    "class MyNet(hk.Module):\n",
    "  def __init__(self, hidden_dim, output_dim, heads, dropout_attention, dropout_nodes, init):\n",
    "    super().__init__()\n",
    "    self.dropout_attention = dropout_attention\n",
    "    self.dropout_nodes = dropout_nodes\n",
    "    self.conv1 = GATConv(hidden_dim, heads=heads, \n",
    "                         dropout=dropout_attention, \n",
    "                         dropout_nodes=dropout_nodes,\n",
    "                         init=init)\n",
    "    self.conv2 = GATConv(output_dim, heads=1, concat=False,\n",
    "                         dropout=dropout_attention, \n",
    "                         dropout_nodes=dropout_nodes, \n",
    "                         init=init)\n",
    "\n",
    "  def __call__(self, graph, training):\n",
    "    nodes, senders, receivers = graph.nodes, graph.senders, graph.receivers\n",
    "    x = nodes\n",
    "\n",
    "    if training:\n",
    "      x = hk.dropout(jax.random.PRNGKey(42), self.dropout_nodes, x)  \n",
    "    x = self.conv1(x, senders, receivers, training=training)\n",
    "    x = jax.nn.elu(x) \n",
    "    \n",
    "    if training:\n",
    "      x = hk.dropout(jax.random.PRNGKey(42), self.dropout_nodes, x)  \n",
    "    x = self.conv2(x, senders, receivers, training=training)\n",
    "    x = jax.nn.softmax(x) # as in the original implementation\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def forward(graph, training, args):\n",
    "  module = MyNet(\n",
    "      args['hidden_dim'], \n",
    "      args['output_dim'],\n",
    "      args['heads'],\n",
    "      args['dropout_attention'],\n",
    "      args['dropout_nodes'],\n",
    "      args['initializer'],\n",
    "  )\n",
    "  return module(graph, training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvemQdQf9RPt"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EHOv2ts9PwF"
   },
   "source": [
    "Transform Haiku module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zd_a0iJHJvCP"
   },
   "outputs": [],
   "source": [
    "rng_key = jax.random.PRNGKey(42)\n",
    "model = hk.without_apply_rng(hk.transform(forward))\n",
    "params = model.init(graph=graph, training=True, args=args, rng=rng_key)\n",
    "output = model.apply(graph=graph, training=True, args=args, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iBDgioMPtVB"
   },
   "source": [
    "Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSX2VEyx3Hm3",
    "outputId": "09109b98-a2f8-493e-d3af-b50221503cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train accuracy: 0.42  Val accuracy 0.31\n",
      "Epoch 10 Train accuracy: 0.96  Val accuracy 0.69\n",
      "Epoch 20 Train accuracy: 0.97  Val accuracy 0.72\n",
      "Epoch 30 Train accuracy: 0.97  Val accuracy 0.72\n",
      "Epoch 40 Train accuracy: 0.97  Val accuracy 0.72\n",
      "Epoch 50 Train accuracy: 0.96  Val accuracy 0.72\n",
      "Epoch 60 Train accuracy: 0.96  Val accuracy 0.72\n",
      "Epoch 70 Train accuracy: 0.96  Val accuracy 0.72\n",
      "Epoch 80 Train accuracy: 0.96  Val accuracy 0.72\n",
      "Epoch 90 Train accuracy: 0.96  Val accuracy 0.72\n",
      "Epoch 100 Train accuracy: 0.96  Val accuracy 0.72\n",
      "Epoch 110 Train accuracy: 0.98  Val accuracy 0.73\n",
      "Epoch 120 Train accuracy: 0.98  Val accuracy 0.73\n",
      "Epoch 130 Train accuracy: 0.98  Val accuracy 0.73\n",
      "Epoch 140 Train accuracy: 0.98  Val accuracy 0.74\n",
      "Epoch 150 Train accuracy: 0.97  Val accuracy 0.75\n",
      "Epoch 160 Train accuracy: 0.97  Val accuracy 0.76\n",
      "Epoch 170 Train accuracy: 0.97  Val accuracy 0.77\n",
      "Epoch 180 Train accuracy: 0.97  Val accuracy 0.77\n",
      "Epoch 190 Train accuracy: 0.97  Val accuracy 0.78\n",
      "Epoch 200 Train accuracy: 0.97  Val accuracy 0.79\n",
      "Epoch 210 Train accuracy: 0.97  Val accuracy 0.79\n",
      "Epoch 220 Train accuracy: 0.97  Val accuracy 0.79\n",
      "Epoch 230 Train accuracy: 0.97  Val accuracy 0.79\n",
      "Epoch 240 Train accuracy: 0.97  Val accuracy 0.79\n",
      "Epoch 250 Train accuracy: 0.97  Val accuracy 0.79\n",
      "Epoch 260 Train accuracy: 0.98  Val accuracy 0.78\n",
      "Epoch 270 Train accuracy: 0.98  Val accuracy 0.78\n",
      "Epoch 280 Train accuracy: 0.99  Val accuracy 0.78\n",
      "Epoch 290 Train accuracy: 0.99  Val accuracy 0.78\n",
      "Epoch 300 Train accuracy: 0.99  Val accuracy 0.78\n",
      "Epoch 310 Train accuracy: 0.99  Val accuracy 0.78\n",
      "Epoch 320 Train accuracy: 0.99  Val accuracy 0.78\n",
      "Epoch 330 Train accuracy: 1.00  Val accuracy 0.77\n",
      "Epoch 340 Train accuracy: 1.00  Val accuracy 0.77\n",
      "Epoch 350 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 360 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 370 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 380 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 390 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 400 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 410 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 420 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 430 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 440 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 450 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 460 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 470 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 480 Train accuracy: 1.00  Val accuracy 0.76\n",
      "Epoch 490 Train accuracy: 1.00  Val accuracy 0.75\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def prediction_loss(params):\n",
    "    logits = model.apply(params=params, graph=graph, training=True, args=args)\n",
    "    logits = logits[train_mask]\n",
    "    one_hot_labels = jax.nn.one_hot(train_labels, NUM_CLASSES)\n",
    "    loss = jnp.sum(optax.softmax_cross_entropy(logits, one_hot_labels))\n",
    "    #jax.debug.print(\"loss {loss}\", loss=loss)\n",
    "    return loss\n",
    "\n",
    "opt_init, opt_update = optax.adamw(args[\"learning_rate\"], weight_decay=args[\"weight_decay\"])\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "@jax.jit\n",
    "def update(params, opt_state):\n",
    "    g = jax.grad(prediction_loss)(params)\n",
    "    updates, opt_state = opt_update(g, opt_state, params=params)\n",
    "    return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "@jax.jit\n",
    "def accuracy_train(params):\n",
    "    decoded_nodes = model.apply(params=params,  graph=graph, training=False, args=args)\n",
    "    decoded_nodes = decoded_nodes[train_mask]\n",
    "    return jnp.mean(jnp.argmax(decoded_nodes, axis=1) == train_labels)\n",
    "\n",
    "@jax.jit\n",
    "def accuracy_val(params):\n",
    "    decoded_nodes = model.apply(params=params, graph=graph, training=False, args=args)\n",
    "    decoded_nodes = decoded_nodes[val_mask]\n",
    "    return jnp.mean(jnp.argmax(decoded_nodes, axis=1) == val_labels)\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_params = None\n",
    "for step in range(args['num_steps']):\n",
    "    params, opt_state = update(params, opt_state)\n",
    "    val_acc = accuracy_val(params).item()\n",
    "    if val_acc > best_acc:\n",
    "      best_acc = val_acc\n",
    "      best_model_params = copy.copy(params)\n",
    "    if step % 10 == 0:\n",
    "      print(f\"Epoch {step} Train accuracy: {accuracy_train(params).item():.2f} \"\n",
    "          f\" Val accuracy {val_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abgyk8qkxTin",
    "outputId": "58692705-2025-4ab5-de8e-9363703bb120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.79\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def test_f(params):\n",
    "    decoded_nodes = model.apply(params=params, graph=graph, training=False, args=args)\n",
    "    decoded_nodes = decoded_nodes[test_mask]\n",
    "    return jnp.mean(jnp.argmax(decoded_nodes, axis=1) == test_labels)\n",
    "\n",
    "print(f\"Test accuracy {test_f(params).item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNGveYI-hXmz"
   },
   "source": [
    "Not bad but needs more regularization / tuning."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
